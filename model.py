# -*- coding: utf-8 -*-
"""hr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zy8vgsS-dsq9RNS2F14qCy7eRSXyWNOq

# Importing Libraries
"""
import pickle
import numpy as np
import pandas as pd
from scipy.stats import skew
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier 
from feature_engine.imputation import CategoricalImputer

"""Read data"""

data = pd.read_csv('train.csv')



"""# Data description"""



"""# Pre-processing data

finding missing columns
"""


"""filling missing values """

data = CategoricalImputer(variables=['education'],imputation_method='frequent').fit_transform(data)

imputer = SimpleImputer(strategy='median', missing_values=np.nan).fit_transform(data[['previous_year_rating']])
data[['previous_year_rating']] = imputer
#data1

"""Seprating target variable"""

X = data.drop(['is_promoted','employee_id'],axis=1)
y = data['is_promoted']

"""segregate"""

X_num = X.select_dtypes(exclude=['object'])
X_num = X_num.drop('awards_won?',axis=1)
X_obj = X.select_dtypes(exclude=['int64','float64'])

"""Label encoding"""
le = LabelEncoder()
oe = OrdinalEncoder()

object_cols = ['department','region','gender','recruitment_channel']

data_oe = pd.DataFrame(oe.fit_transform(X_obj[object_cols]))
data_oe.columns = object_cols
"""One hot encoding"""

data_ohe = pd.get_dummies(X['education'], columns = ['education'])
def transform(x):
    if round(skew(x),1) > 1 :
        if pd.Series(x<=0).any() :
            x = np.log(x+1.5)
            #print('significantly positive skewed with 0 values')
        else :
            x = np.log(x)
            #print('significantly positive skewed')
    elif round(skew(x),1) > 0.5  :
        x = np.sqrt(x)
        #print('moderately positive skewed')
    elif round(skew(x),1) < -1 :
        x = np.log(2-x)
        #print('significantly negetive skewed')
    elif round(skew(x),1) < -0.5 :
        x = np.sqrt(2-x)
        #print('moderately negetive skewed')
    else :
        None 
        #print('approx symmetric')
    
    return x

X_transform = X_num.apply(lambda x : transform(x))
X_final = pd.concat([X_transform,data_oe, X['awards_won?'],data_ohe, ],axis=1)
X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.33 , random_state=5 , stratify = y )
classifier = DecisionTreeClassifier(max_depth=10).fit(X_train, y_train)
print(X_final)
predict = classifier.predict(X_test)
pickle.dump(classifier, open('model.pkl','wb'))
#load the model and test with a custom input
model = pickle.load( open('model.pkl','rb'))
